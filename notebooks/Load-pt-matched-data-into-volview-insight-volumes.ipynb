{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading patient-matched EHR and CXR data into VolView Insight (Docker Volumes)\n",
    "\n",
    "This notebook loads patient-matched chest X-Ray and EHR data into **local Docker volumes** instead of uploading to running servers. The data is saved in the exact format that Docker containers expect.\n",
    "\n",
    "## Key Changes:\n",
    "- ✅ **No server dependencies** - works without HAPI FHIR or Orthanc running\n",
    "- ✅ **Docker volume format** - data saved in format containers expect\n",
    "- ✅ **Automatic mounting** - docker-compose automatically mounts the volumes\n",
    "- ✅ **Version control friendly** - uses relative paths\n",
    "\n",
    "## Directory Structure Created:\n",
    "```\n",
    "volumes/\n",
    "├── hapi-fhir-data/\n",
    "│   ├── patients.json                    # All patient data\n",
    "│   ├── patient_[id].json               # Individual patient files\n",
    "│   ├── condition/\n",
    "│   │   └── condition.json\n",
    "│   ├── encounter/\n",
    "│   │   └── encounter.json\n",
    "│   └── ... (other resource types)\n",
    "└── orthanc-data/\n",
    "    ├── patient_10000032/\n",
    "    │   ├── 02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.dcm\n",
    "    │   └── ... (other DICOM files)\n",
    "    ├── patient_10000764/\n",
    "    │   └── ... (DICOM files)\n",
    "    └── dicom_metadata.json              # Metadata about copied files\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 Environment Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume paths:\n",
      "  FHIR data: /home/local/KHQ/andinet.enquobahrie/s/volview-insight-docker/volumes/hapi-fhir-data\n",
      "  Orthanc data: /home/local/KHQ/andinet.enquobahrie/s/volview-insight-docker/volumes/orthanc-data\n"
     ]
    }
   ],
   "source": [
    "from fhirclient.models.patient import Patient\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "PROJECT_ID = \"Load-pt-matched-data-into-volview-insight-volumes\"\n",
    "\n",
    "# Local directory paths\n",
    "PROJECT_ROOT = Path(\"/home/local/KHQ/andinet.enquobahrie/data/volview_insight-internal\")\n",
    "MIMIC_IV_BASE = Path(\"/home/local/KHQ/andinet.enquobahrie/mnt/physionet/physionet.org/files/mimiciv/3.1/\")\n",
    "MIMIC_CXR_BASE = Path(\"/home/local/KHQ/andinet.enquobahrie/mnt/physionet/physionet.org/files/mimic-cxr/2.0.0/\")\n",
    "MIMIC_IV_FHIR_BASE = Path(\"/home/local/KHQ/andinet.enquobahrie/mnt/physionet/physionet.org/files/mimic-iv-fhir/2.1/\")\n",
    "\n",
    "# Docker volume paths (relative to volview-insight project root)\n",
    "# These paths should match the docker-compose.yml volume bindings\n",
    "VOLVIEW_INSIGHT_ROOT = Path(\"/home/local/KHQ/andinet.enquobahrie/s/volview-insight-docker\")\n",
    "LOCAL_FHIR_VOLUME = VOLVIEW_INSIGHT_ROOT / \"volumes\" / \"hapi-fhir-data\"\n",
    "LOCAL_ORTHANC_VOLUME = VOLVIEW_INSIGHT_ROOT / \"volumes\" / \"orthanc-data\"\n",
    "\n",
    "print(f\"Volume paths:\")\n",
    "print(f\"  FHIR data: {LOCAL_FHIR_VOLUME}\")\n",
    "print(f\"  Orthanc data: {LOCAL_ORTHANC_VOLUME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created volume directories:\n",
      "  FHIR data: /home/local/KHQ/andinet.enquobahrie/s/volview-insight-docker/volumes/hapi-fhir-data\n",
      "  Orthanc data: /home/local/KHQ/andinet.enquobahrie/s/volview-insight-docker/volumes/orthanc-data\n",
      "  FHIR exists: True\n",
      "  Orthanc exists: True\n"
     ]
    }
   ],
   "source": [
    "# Create Docker volume directories\n",
    "LOCAL_FHIR_VOLUME.mkdir(parents=True, exist_ok=True)\n",
    "LOCAL_ORTHANC_VOLUME.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Created volume directories:\")\n",
    "print(f\"  FHIR data: {LOCAL_FHIR_VOLUME}\")\n",
    "print(f\"  Orthanc data: {LOCAL_ORTHANC_VOLUME}\")\n",
    "print(f\"  FHIR exists: {LOCAL_FHIR_VOLUME.exists()}\")\n",
    "print(f\"  Orthanc exists: {LOCAL_ORTHANC_VOLUME.exists()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📂 Data Access and Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>anchor_year</th>\n",
       "      <th>anchor_year_group</th>\n",
       "      <th>dod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>2180</td>\n",
       "      <td>2014 - 2016</td>\n",
       "      <td>2180-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000048</td>\n",
       "      <td>F</td>\n",
       "      <td>23</td>\n",
       "      <td>2126</td>\n",
       "      <td>2008 - 2010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000058</td>\n",
       "      <td>F</td>\n",
       "      <td>33</td>\n",
       "      <td>2168</td>\n",
       "      <td>2020 - 2022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000068</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>2160</td>\n",
       "      <td>2008 - 2010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000084</td>\n",
       "      <td>M</td>\n",
       "      <td>72</td>\n",
       "      <td>2160</td>\n",
       "      <td>2017 - 2019</td>\n",
       "      <td>2161-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364622</th>\n",
       "      <td>19999828</td>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>2147</td>\n",
       "      <td>2017 - 2019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364623</th>\n",
       "      <td>19999829</td>\n",
       "      <td>F</td>\n",
       "      <td>28</td>\n",
       "      <td>2186</td>\n",
       "      <td>2008 - 2010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364624</th>\n",
       "      <td>19999840</td>\n",
       "      <td>M</td>\n",
       "      <td>58</td>\n",
       "      <td>2164</td>\n",
       "      <td>2008 - 2010</td>\n",
       "      <td>2164-09-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364625</th>\n",
       "      <td>19999914</td>\n",
       "      <td>F</td>\n",
       "      <td>49</td>\n",
       "      <td>2158</td>\n",
       "      <td>2017 - 2019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364626</th>\n",
       "      <td>19999987</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>2145</td>\n",
       "      <td>2011 - 2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364627 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        subject_id gender  anchor_age  anchor_year anchor_year_group  \\\n",
       "0         10000032      F          52         2180       2014 - 2016   \n",
       "1         10000048      F          23         2126       2008 - 2010   \n",
       "2         10000058      F          33         2168       2020 - 2022   \n",
       "3         10000068      F          19         2160       2008 - 2010   \n",
       "4         10000084      M          72         2160       2017 - 2019   \n",
       "...            ...    ...         ...          ...               ...   \n",
       "364622    19999828      F          46         2147       2017 - 2019   \n",
       "364623    19999829      F          28         2186       2008 - 2010   \n",
       "364624    19999840      M          58         2164       2008 - 2010   \n",
       "364625    19999914      F          49         2158       2017 - 2019   \n",
       "364626    19999987      F          57         2145       2011 - 2013   \n",
       "\n",
       "               dod  \n",
       "0       2180-09-09  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4       2161-02-13  \n",
       "...            ...  \n",
       "364622         NaN  \n",
       "364623         NaN  \n",
       "364624  2164-09-17  \n",
       "364625         NaN  \n",
       "364626         NaN  \n",
       "\n",
       "[364627 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MIMIC-IV patients dataframe\n",
    "patients_df = pd.read_csv(MIMIC_IV_BASE / \"hosp/patients.csv.gz\")\n",
    "patients_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 377110 image records from MIMIC-CXR\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>dicom_id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>50414267</td>\n",
       "      <td>02aa804e-bde0afdd-112c0b34-7bc16630-4e384014</td>\n",
       "      <td>files/p10/p10000032/s50414267/02aa804e-bde0afd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>50414267</td>\n",
       "      <td>174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962</td>\n",
       "      <td>files/p10/p10000032/s50414267/174413ec-4ec4c1f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>53189527</td>\n",
       "      <td>2a2277a9-b0ded155-c0de8eb9-c124d10e-82c5caab</td>\n",
       "      <td>files/p10/p10000032/s53189527/2a2277a9-b0ded15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032</td>\n",
       "      <td>53189527</td>\n",
       "      <td>e084de3b-be89b11e-20fe3f9f-9c8d8dfe-4cfd202c</td>\n",
       "      <td>files/p10/p10000032/s53189527/e084de3b-be89b11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000032</td>\n",
       "      <td>53911762</td>\n",
       "      <td>68b5c4b1-227d0485-9cc38c3f-7b84ab51-4b472714</td>\n",
       "      <td>files/p10/p10000032/s53911762/68b5c4b1-227d048...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377105</th>\n",
       "      <td>19999733</td>\n",
       "      <td>57132437</td>\n",
       "      <td>428e2c18-5721d8f3-35a05001-36f3d080-9053b83c</td>\n",
       "      <td>files/p19/p19999733/s57132437/428e2c18-5721d8f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377106</th>\n",
       "      <td>19999733</td>\n",
       "      <td>57132437</td>\n",
       "      <td>58c403aa-35ff8bd9-73e39f54-8dc9cc5d-e0ec3fa9</td>\n",
       "      <td>files/p19/p19999733/s57132437/58c403aa-35ff8bd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377107</th>\n",
       "      <td>19999987</td>\n",
       "      <td>55368167</td>\n",
       "      <td>58766883-376a15ce-3b323a28-6af950a0-16b793bd</td>\n",
       "      <td>files/p19/p19999987/s55368167/58766883-376a15c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377108</th>\n",
       "      <td>19999987</td>\n",
       "      <td>58621812</td>\n",
       "      <td>7ba273af-3d290f8d-e28d0ab4-484b7a86-7fc12b08</td>\n",
       "      <td>files/p19/p19999987/s58621812/7ba273af-3d290f8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377109</th>\n",
       "      <td>19999987</td>\n",
       "      <td>58971208</td>\n",
       "      <td>1a1fe7e3-cbac5d93-b339aeda-86bb86b5-4f31e82e</td>\n",
       "      <td>files/p19/p19999987/s58971208/1a1fe7e3-cbac5d9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>377110 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        subject_id  study_id                                      dicom_id  \\\n",
       "0         10000032  50414267  02aa804e-bde0afdd-112c0b34-7bc16630-4e384014   \n",
       "1         10000032  50414267  174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962   \n",
       "2         10000032  53189527  2a2277a9-b0ded155-c0de8eb9-c124d10e-82c5caab   \n",
       "3         10000032  53189527  e084de3b-be89b11e-20fe3f9f-9c8d8dfe-4cfd202c   \n",
       "4         10000032  53911762  68b5c4b1-227d0485-9cc38c3f-7b84ab51-4b472714   \n",
       "...            ...       ...                                           ...   \n",
       "377105    19999733  57132437  428e2c18-5721d8f3-35a05001-36f3d080-9053b83c   \n",
       "377106    19999733  57132437  58c403aa-35ff8bd9-73e39f54-8dc9cc5d-e0ec3fa9   \n",
       "377107    19999987  55368167  58766883-376a15ce-3b323a28-6af950a0-16b793bd   \n",
       "377108    19999987  58621812  7ba273af-3d290f8d-e28d0ab4-484b7a86-7fc12b08   \n",
       "377109    19999987  58971208  1a1fe7e3-cbac5d93-b339aeda-86bb86b5-4f31e82e   \n",
       "\n",
       "                                                     path  \n",
       "0       files/p10/p10000032/s50414267/02aa804e-bde0afd...  \n",
       "1       files/p10/p10000032/s50414267/174413ec-4ec4c1f...  \n",
       "2       files/p10/p10000032/s53189527/2a2277a9-b0ded15...  \n",
       "3       files/p10/p10000032/s53189527/e084de3b-be89b11...  \n",
       "4       files/p10/p10000032/s53911762/68b5c4b1-227d048...  \n",
       "...                                                   ...  \n",
       "377105  files/p19/p19999733/s57132437/428e2c18-5721d8f...  \n",
       "377106  files/p19/p19999733/s57132437/58c403aa-35ff8bd...  \n",
       "377107  files/p19/p19999987/s55368167/58766883-376a15c...  \n",
       "377108  files/p19/p19999987/s58621812/7ba273af-3d290f8...  \n",
       "377109  files/p19/p19999987/s58971208/1a1fe7e3-cbac5d9...  \n",
       "\n",
       "[377110 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MIMIC-CXR chest X-Ray records dataframe\n",
    "image_record_df = pd.read_csv(MIMIC_CXR_BASE / \"cxr-record-list.csv.gz\")\n",
    "print(f\"Loaded {len(image_record_df)} image records from MIMIC-CXR\")\n",
    "image_record_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 61868 patients with both EHR and imaging data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>anchor_year</th>\n",
       "      <th>anchor_year_group</th>\n",
       "      <th>dod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>2180</td>\n",
       "      <td>2014 - 2016</td>\n",
       "      <td>2180-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10000764</td>\n",
       "      <td>M</td>\n",
       "      <td>86</td>\n",
       "      <td>2132</td>\n",
       "      <td>2014 - 2016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10000898</td>\n",
       "      <td>F</td>\n",
       "      <td>80</td>\n",
       "      <td>2188</td>\n",
       "      <td>2014 - 2016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10000935</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>2182</td>\n",
       "      <td>2008 - 2010</td>\n",
       "      <td>2187-11-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10000980</td>\n",
       "      <td>F</td>\n",
       "      <td>73</td>\n",
       "      <td>2186</td>\n",
       "      <td>2008 - 2010</td>\n",
       "      <td>2193-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364603</th>\n",
       "      <td>19999287</td>\n",
       "      <td>F</td>\n",
       "      <td>71</td>\n",
       "      <td>2191</td>\n",
       "      <td>2008 - 2010</td>\n",
       "      <td>2197-09-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364609</th>\n",
       "      <td>19999376</td>\n",
       "      <td>M</td>\n",
       "      <td>44</td>\n",
       "      <td>2145</td>\n",
       "      <td>2011 - 2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364611</th>\n",
       "      <td>19999442</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>2146</td>\n",
       "      <td>2008 - 2010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364618</th>\n",
       "      <td>19999733</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>2152</td>\n",
       "      <td>2011 - 2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364626</th>\n",
       "      <td>19999987</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>2145</td>\n",
       "      <td>2011 - 2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61868 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        subject_id gender  anchor_age  anchor_year anchor_year_group  \\\n",
       "0         10000032      F          52         2180       2014 - 2016   \n",
       "26        10000764      M          86         2132       2014 - 2016   \n",
       "31        10000898      F          80         2188       2014 - 2016   \n",
       "33        10000935      F          52         2182       2008 - 2010   \n",
       "38        10000980      F          73         2186       2008 - 2010   \n",
       "...            ...    ...         ...          ...               ...   \n",
       "364603    19999287      F          71         2191       2008 - 2010   \n",
       "364609    19999376      M          44         2145       2011 - 2013   \n",
       "364611    19999442      M          41         2146       2008 - 2010   \n",
       "364618    19999733      F          19         2152       2011 - 2013   \n",
       "364626    19999987      F          57         2145       2011 - 2013   \n",
       "\n",
       "               dod  \n",
       "0       2180-09-09  \n",
       "26             NaN  \n",
       "31             NaN  \n",
       "33      2187-11-12  \n",
       "38      2193-08-26  \n",
       "...            ...  \n",
       "364603  2197-09-02  \n",
       "364609         NaN  \n",
       "364611         NaN  \n",
       "364618         NaN  \n",
       "364626         NaN  \n",
       "\n",
       "[61868 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter patients to only those with images\n",
    "patients_df = patients_df[patients_df['subject_id'].isin(image_record_df['subject_id'])]\n",
    "print(f\"Found {len(patients_df)} patients with both EHR and imaging data\")\n",
    "patients_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>files/p10/p10000032/s50414267/02aa804e-bde0afd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>files/p10/p10000032/s50414267/174413ec-4ec4c1f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>files/p10/p10000032/s53189527/2a2277a9-b0ded15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032</td>\n",
       "      <td>files/p10/p10000032/s53189527/e084de3b-be89b11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000032</td>\n",
       "      <td>files/p10/p10000032/s53911762/68b5c4b1-227d048...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>10001401</td>\n",
       "      <td>files/p10/p10001401/s55350604/d9db838d-4612fd1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>10001401</td>\n",
       "      <td>files/p10/p10001401/s56534136/d69651ae-dc7bacc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>10001401</td>\n",
       "      <td>files/p10/p10001401/s57492692/a83c7ff9-2d42639...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>10001401</td>\n",
       "      <td>files/p10/p10001401/s58747570/19e55bee-714bb19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>10001401</td>\n",
       "      <td>files/p10/p10001401/s58747570/f56a3d51-284b246...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject_id                                               path\n",
       "0     10000032  files/p10/p10000032/s50414267/02aa804e-bde0afd...\n",
       "1     10000032  files/p10/p10000032/s50414267/174413ec-4ec4c1f...\n",
       "2     10000032  files/p10/p10000032/s53189527/2a2277a9-b0ded15...\n",
       "3     10000032  files/p10/p10000032/s53189527/e084de3b-be89b11...\n",
       "4     10000032  files/p10/p10000032/s53911762/68b5c4b1-227d048...\n",
       "..         ...                                                ...\n",
       "62    10001401  files/p10/p10001401/s55350604/d9db838d-4612fd1...\n",
       "63    10001401  files/p10/p10001401/s56534136/d69651ae-dc7bacc...\n",
       "64    10001401  files/p10/p10001401/s57492692/a83c7ff9-2d42639...\n",
       "65    10001401  files/p10/p10001401/s58747570/19e55bee-714bb19...\n",
       "66    10001401  files/p10/p10001401/s58747570/f56a3d51-284b246...\n",
       "\n",
       "[67 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose 10 patients with images\n",
    "selected_patients = patients_df.iloc[:10]['subject_id']\n",
    "selected_images = image_record_df[image_record_df['subject_id'].isin(selected_patients)][['subject_id', 'path']]\n",
    "\n",
    "selected_images\n",
    "#print(f\"Selected {len(selected_patients)} patients:\")\n",
    "#for patient_id in selected_patients:\n",
    "#    patient_images = selected_images[selected_images['subject_id'] == patient_id]\n",
    "#    print(f\"  Patient {patient_id}: {len(patient_images)} images\")\n",
    "\n",
    "#print(f\"\\nTotal images to process: {len(selected_images)}\")\n",
    "#selected_images.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💾 Save FHIR Patient Resources to Local Volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FHIR Patient resources...\n",
      "Saved Patient 10000032 to patient_0a8eebfd-a352-522e-89f0-1d4a13abdebc.json\n",
      "Saved Patient 10000764 to patient_62c0431d-ad3e-5f73-a4e0-b2358beacf78.json\n",
      "Saved Patient 10000898 to patient_67dbcef1-d72b-545a-a9cf-6b2587f8a628.json\n",
      "Saved Patient 10000935 to patient_7f448141-4f68-5e99-88aa-0dedae4bcfcd.json\n",
      "Saved Patient 10000980 to patient_b9751acd-fc69-520d-b2e6-f7e232dbea03.json\n",
      "Saved Patient 10001038 to patient_e6cebc51-37de-5ced-8f9b-fdac06a2fc71.json\n",
      "Saved Patient 10001122 to patient_d377090e-f214-5fc2-a883-671ede9a7463.json\n",
      "Saved Patient 10001176 to patient_7efc6f11-1cb4-5d64-8dcd-7c66ef1b90fc.json\n",
      "Saved Patient 10001217 to patient_a6e7e991-6801-5425-b435-4ca6b7decfcc.json\n",
      "Saved Patient 10001401 to patient_f22618de-6490-5e23-a1c4-4de3f02a7b97.json\n",
      "\n",
      "✅ Saved 10 patients to patients.json\n",
      "📁 Individual patient files saved to: /home/local/KHQ/andinet.enquobahrie/s/volview-insight-docker/volumes/hapi-fhir-data\n"
     ]
    }
   ],
   "source": [
    "# Save FHIR Patient resources to local volume instead of uploading to server\n",
    "# Make sure to save the MimicPatient \"id\", which is the unique reference to the patient\n",
    "# as it pertains to the FHIR system from which the data was transferred.\n",
    "\n",
    "# Convert Series to DataFrame\n",
    "if isinstance(selected_patients, pd.Series):\n",
    "    selected_patients = selected_patients.to_frame(name='subject_id')\n",
    "    \n",
    "# Add the column with default None (if it doesn't exist already)\n",
    "if 'orig_patient_reference' not in selected_patients.columns:\n",
    "    selected_patients['orig_patient_reference'] = None\n",
    "\n",
    "# Save patient data to local volume\n",
    "patient_data = []\n",
    "print(\"Processing FHIR Patient resources...\")\n",
    "\n",
    "with gzip.open(MIMIC_IV_FHIR_BASE / \"fhir\" / \"MimicPatient.ndjson.gz\", 'rt') as f:\n",
    "    for line in f:\n",
    "        patient_json = json.loads(line)\n",
    "        subject_id = int(patient_json[\"identifier\"][0][\"value\"])\n",
    "        if subject_id in selected_patients['subject_id'].values:\n",
    "            patient_data.append(patient_json)\n",
    "            selected_patients.loc[selected_patients['subject_id'] == subject_id, 'orig_patient_reference'] = patient_json[\"id\"]\n",
    "            \n",
    "            # Save individual patient file\n",
    "            patient_file = LOCAL_FHIR_VOLUME / f\"patient_{patient_json['id']}.json\"\n",
    "            with open(patient_file, 'w') as pf:\n",
    "                json.dump(patient_json, pf, indent=2)\n",
    "            print(f\"Saved Patient {subject_id} to {patient_file.name}\")\n",
    "\n",
    "# Save all patient data to a single file for easy loading\n",
    "patients_file = LOCAL_FHIR_VOLUME / \"patients.json\"\n",
    "with open(patients_file, 'w') as f:\n",
    "    json.dump(patient_data, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Saved {len(patient_data)} patients to {patients_file.name}\")\n",
    "print(f\"📁 Individual patient files saved to: {LOCAL_FHIR_VOLUME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏥 Copy DICOM Files to Local Volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying DICOM files to local volume...\n",
      "Processed 10/67 files...\n",
      "Processed 20/67 files...\n",
      "Processed 30/67 files...\n",
      "Processed 40/67 files...\n",
      "Processed 50/67 files...\n",
      "Processed 60/67 files...\n",
      "\n",
      "✅ Copied 67 DICOM files to /home/local/KHQ/andinet.enquobahrie/s/volview-insight-docker/volumes/orthanc-data\n",
      "📁 Metadata saved to: dicom_metadata.json\n",
      "\n",
      "📊 Summary by patient:\n",
      "  Patient 10000032: 7 files (99.8 MB)\n",
      "  Patient 10000764: 3 files (44.5 MB)\n",
      "  Patient 10000898: 5 files (74.2 MB)\n",
      "  Patient 10000935: 10 files (115.3 MB)\n",
      "  Patient 10000980: 16 files (208.4 MB)\n",
      "  Patient 10001038: 3 files (44.5 MB)\n",
      "  Patient 10001122: 5 files (58.9 MB)\n",
      "  Patient 10001176: 5 files (53.3 MB)\n",
      "  Patient 10001217: 3 files (44.4 MB)\n",
      "  Patient 10001401: 10 files (134.4 MB)\n"
     ]
    }
   ],
   "source": [
    "# Copy DICOM files to local volume instead of uploading to Orthanc server\n",
    "print(\"Copying DICOM files to local volume...\")\n",
    "\n",
    "dicom_files_copied = []\n",
    "total_files = len(selected_images)\n",
    "processed_files = 0\n",
    "\n",
    "for idx, row in selected_images.iterrows():\n",
    "    source_path = MIMIC_CXR_BASE / row['path']\n",
    "    \n",
    "    if not source_path.exists():\n",
    "        print(f\"[Warning] File not found: {source_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Create patient-specific directory\n",
    "    patient_dir = LOCAL_ORTHANC_VOLUME / f\"patient_{row['subject_id']}\"\n",
    "    patient_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Copy DICOM file\n",
    "    dest_path = patient_dir / source_path.name\n",
    "    shutil.copy2(source_path, dest_path)\n",
    "    \n",
    "    dicom_files_copied.append({\n",
    "        'subject_id': row['subject_id'],\n",
    "        'source_path': str(source_path),\n",
    "        'dest_path': str(dest_path),\n",
    "        'file_size': dest_path.stat().st_size\n",
    "    })\n",
    "    \n",
    "    processed_files += 1\n",
    "    if processed_files % 10 == 0:\n",
    "        print(f\"Processed {processed_files}/{total_files} files...\")\n",
    "\n",
    "# Save metadata about copied files\n",
    "metadata_file = LOCAL_ORTHANC_VOLUME / \"dicom_metadata.json\"\n",
    "with open(metadata_file, 'w') as f:\n",
    "    json.dump(dicom_files_copied, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Copied {len(dicom_files_copied)} DICOM files to {LOCAL_ORTHANC_VOLUME}\")\n",
    "print(f\"📁 Metadata saved to: {metadata_file.name}\")\n",
    "\n",
    "# Show summary by patient\n",
    "print(f\"\\n📊 Summary by patient:\")\n",
    "for patient_id in selected_patients['subject_id']:\n",
    "    patient_files = [f for f in dicom_files_copied if f['subject_id'] == patient_id]\n",
    "    total_size = sum(f['file_size'] for f in patient_files)\n",
    "    print(f\"  Patient {patient_id}: {len(patient_files)} files ({total_size / 1024 / 1024:.1f} MB)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 Save Other FHIR Resources to Local Volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing other FHIR resources...\n",
      "\n",
      "Processing Condition...\n",
      "✅ 415 Condition resources saved to condition.json in 54.07 seconds\n",
      "\n",
      "Processing Encounter...\n",
      "✅ 26 Encounter resources saved to encounter.json in 9.01 seconds\n",
      "\n",
      "Processing Medication...\n",
      "Skipping Medication because resources are not linked to patients\n",
      "✅ 0 Medication resources saved to medication.json in 0.02 seconds\n",
      "\n",
      "Processing MedicationAdministration...\n",
      "✅ 1745 MedicationAdministration resources saved to medicationadministration.json in 370.78 seconds\n",
      "\n",
      "Processing MedicationDispense...\n",
      "✅ 815 MedicationDispense resources saved to medicationdispense.json in 184.27 seconds\n",
      "\n",
      "Processing MedicationRequest...\n",
      "✅ 1031 MedicationRequest resources saved to medicationrequest.json in 233.35 seconds\n",
      "\n",
      "Processing ObservationChartevents...\n",
      "✅ 3559 ObservationChartevents resources saved to observationchartevents.json in 3961.55 seconds\n",
      "\n",
      "Processing Organization...\n",
      "Skipping Organization because resources are not linked to patients\n",
      "✅ 0 Organization resources saved to organization.json in 0.00 seconds\n",
      "\n",
      "Processing Procedure...\n",
      "✅ 42 Procedure resources saved to procedure.json in 7.15 seconds\n",
      "\n",
      "🎉 All FHIR resources saved to /home/local/KHQ/andinet.enquobahrie/s/volview-insight-docker/volumes/hapi-fhir-data\n",
      "📊 Total resources saved: 7633\n"
     ]
    }
   ],
   "source": [
    "# Save other FHIR resources to local volume instead of uploading to HAPI FHIR server\n",
    "BASE_FHIR_RESOURCES = [\"Condition\", \"Encounter\", \"Medication\",\n",
    "\"MedicationAdministration\", \"MedicationDispense\", \"MedicationRequest\",\n",
    "\"ObservationChartevents\", \"Organization\", \"Patient\", \"Procedure\"]\n",
    "\n",
    "RESOURCE_FILES = [MIMIC_IV_FHIR_BASE / \"fhir\" / (\"Mimic\" + resource + \".ndjson.gz\") for resource in BASE_FHIR_RESOURCES if resource != \"Patient\"]\n",
    "\n",
    "# Create resource-specific directories\n",
    "for resource in BASE_FHIR_RESOURCES:\n",
    "    if resource != \"Patient\":\n",
    "        (LOCAL_FHIR_VOLUME / resource.lower()).mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Processing other FHIR resources...\")\n",
    "\n",
    "# Process and save resources\n",
    "total_resources_saved = 0\n",
    "for file in RESOURCE_FILES:\n",
    "    resource_type = file.name.replace(\"Mimic\", \"\").replace(\".ndjson.gz\", \"\").split('.')[0]\n",
    "    print(f\"\\nProcessing {resource_type}...\")\n",
    "    \n",
    "    resource_data = []\n",
    "    success_count = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with gzip.open(file, 'rt') as f:\n",
    "        for line in f:\n",
    "            resource_json = json.loads(line)\n",
    "            \n",
    "            if \"subject\" not in resource_json or \"reference\" not in resource_json[\"subject\"]:\n",
    "                print(f\"Skipping {resource_type} because resources are not linked to patients\")\n",
    "                break\n",
    "                \n",
    "            orig_patient_reference = resource_json[\"subject\"][\"reference\"].split(\"/\")[1]\n",
    "            \n",
    "            if orig_patient_reference not in selected_patients['orig_patient_reference'].values:\n",
    "                continue\n",
    "            \n",
    "            resource_data.append(resource_json)\n",
    "            success_count += 1\n",
    "    \n",
    "    # Save all resources of this type to a single file\n",
    "    resource_file = LOCAL_FHIR_VOLUME / resource_type.lower() / f\"{resource_type.lower()}.json\"\n",
    "    with open(resource_file, 'w') as f:\n",
    "        json.dump(resource_data, f, indent=2)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    print(f\"✅ {success_count} {resource_type} resources saved to {resource_file.name} in {elapsed:.2f} seconds\")\n",
    "    total_resources_saved += success_count\n",
    "\n",
    "print(f\"\\n🎉 All FHIR resources saved to {LOCAL_FHIR_VOLUME}\")\n",
    "print(f\"📊 Total resources saved: {total_resources_saved}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Summary and Next Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 Data Loading Complete!\n",
      "==================================================\n",
      "\n",
      "📁 Volume Directories Created:\n",
      "  FHIR data: /home/local/KHQ/andinet.enquobahrie/s/volview-insight-docker/volumes/hapi-fhir-data\n",
      "  Orthanc data: /home/local/KHQ/andinet.enquobahrie/s/volview-insight-docker/volumes/orthanc-data\n",
      "\n",
      "👥 Patients Processed: 10\n",
      "🏥 DICOM Files Copied: 67\n",
      "📋 FHIR Resources Saved: 7633\n",
      "\n",
      "📂 Directory Structure:\n",
      "volumes/\n",
      "├── hapi-fhir-data/\n",
      "│   ├── patients.json\n",
      "│   ├── patient_*.json\n",
      "│   ├── condition/\n",
      "│   │   └── condition.json\n",
      "│   ├── encounter/\n",
      "│   │   └── encounter.json\n",
      "│   ├── medication/\n",
      "│   │   └── medication.json\n",
      "│   ├── medicationadministration/\n",
      "│   │   └── medicationadministration.json\n",
      "│   ├── medicationdispense/\n",
      "│   │   └── medicationdispense.json\n",
      "│   ├── medicationrequest/\n",
      "│   │   └── medicationrequest.json\n",
      "│   ├── observationchartevents/\n",
      "│   │   └── observationchartevents.json\n",
      "│   ├── organization/\n",
      "│   │   └── organization.json\n",
      "│   ├── procedure/\n",
      "│   │   └── procedure.json\n",
      "└── orthanc-data/\n",
      "    ├── patient_10000032/\n",
      "    │   └── 7 DICOM files\n",
      "    ├── patient_10000764/\n",
      "    │   └── 3 DICOM files\n",
      "    ├── patient_10000898/\n",
      "    │   └── 5 DICOM files\n",
      "    ├── patient_10000935/\n",
      "    │   └── 10 DICOM files\n",
      "    ├── patient_10000980/\n",
      "    │   └── 16 DICOM files\n",
      "    ├── patient_10001038/\n",
      "    │   └── 3 DICOM files\n",
      "    ├── patient_10001122/\n",
      "    │   └── 5 DICOM files\n",
      "    ├── patient_10001176/\n",
      "    │   └── 5 DICOM files\n",
      "    ├── patient_10001217/\n",
      "    │   └── 3 DICOM files\n",
      "    ├── patient_10001401/\n",
      "    │   └── 10 DICOM files\n",
      "    └── dicom_metadata.json\n",
      "\n",
      "🚀 Next Steps:\n",
      "1. Start Docker Compose: docker-compose up -d\n",
      "2. Access VolView Insight: http://localhost:8080\n",
      "3. The data will be automatically available in the containers!\n",
      "\n",
      "💡 Benefits:\n",
      "✅ No server dependencies during data preparation\n",
      "✅ Data persists between container restarts\n",
      "✅ Version control friendly (relative paths)\n",
      "✅ Easy to share and reproduce\n",
      "✅ Docker automatically mounts the volumes\n"
     ]
    }
   ],
   "source": [
    "# Summary of what was created\n",
    "print(\"🎉 Data Loading Complete!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n📁 Volume Directories Created:\")\n",
    "print(f\"  FHIR data: {LOCAL_FHIR_VOLUME}\")\n",
    "print(f\"  Orthanc data: {LOCAL_ORTHANC_VOLUME}\")\n",
    "\n",
    "print(f\"\\n👥 Patients Processed: {len(selected_patients)}\")\n",
    "print(f\"🏥 DICOM Files Copied: {len(dicom_files_copied)}\")\n",
    "print(f\"📋 FHIR Resources Saved: {total_resources_saved}\")\n",
    "\n",
    "print(f\"\\n📂 Directory Structure:\")\n",
    "print(f\"volumes/\")\n",
    "print(f\"├── hapi-fhir-data/\")\n",
    "print(f\"│   ├── patients.json\")\n",
    "print(f\"│   ├── patient_*.json\")\n",
    "for resource in BASE_FHIR_RESOURCES:\n",
    "    if resource != \"Patient\":\n",
    "        print(f\"│   ├── {resource.lower()}/\")\n",
    "        print(f\"│   │   └── {resource.lower()}.json\")\n",
    "print(f\"└── orthanc-data/\")\n",
    "for patient_id in selected_patients['subject_id']:\n",
    "    patient_files = [f for f in dicom_files_copied if f['subject_id'] == patient_id]\n",
    "    print(f\"    ├── patient_{patient_id}/\")\n",
    "    print(f\"    │   └── {len(patient_files)} DICOM files\")\n",
    "print(f\"    └── dicom_metadata.json\")\n",
    "\n",
    "print(f\"\\n🚀 Next Steps:\")\n",
    "print(f\"1. Start Docker Compose: docker-compose up -d\")\n",
    "print(f\"2. Access VolView Insight: http://localhost:8080\")\n",
    "print(f\"3. The data will be automatically available in the containers!\")\n",
    "\n",
    "print(f\"\\n💡 Benefits:\")\n",
    "print(f\"✅ No server dependencies during data preparation\")\n",
    "print(f\"✅ Data persists between container restarts\")\n",
    "print(f\"✅ Version control friendly (relative paths)\")\n",
    "print(f\"✅ Easy to share and reproduce\")\n",
    "print(f\"✅ Docker automatically mounts the volumes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VolView Insight Kernel",
   "language": "python",
   "name": "volviewinsight-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
