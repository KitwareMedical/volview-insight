{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1c475c9-30bd-478d-8269-aa39ae9f4440",
   "metadata": {},
   "source": [
    "# Loading patient-matched EHR and CXR data into VolView Insight\n",
    "\n",
    "The goal of this notebook is to be a lightweight example of loading patient-matched chest X-Ray and EHR data into the [VolView Insight web app](https://github.com/KitwareMedical/volview-insight). You will need access to matching example data (matching meaning both images and EHR data for the same patient). In this example, MIMIC data were used. MIMIC-CXR is a standard database of DICOM chest X-ray data, and it is several terabytes. If you are trying to load in this data at Kitware Medical, there is a NAS system that has all this data pre-installed. Please ask around for access to the NAS system, which has all of the data (MIMIC-IV, MIMIC-CXR, and MIMIC-IV FHIR). Once you can access the NAS, find a way to mount the directory containing the MIMIC data to the computer where you're running this notebook.  On the NAS, the data should be at `/volume1/data/physionet.org/files/`, unless things have changed since this notebook was written. Then, once the NAS is mounted onto your computer, create a symlink to the location of the data (to `/volume1/data/`).\n",
    "\n",
    "Assuming that `PROJECT_ROOT` is the root of this repository, and that you have made a symlink `PROJECT_ROOT/local` point to `/the/mounted/location/of/volume1/data`, the paths in this notebook should work seamlessly. Lastly, you may have to tune the URLs for the HAPI FHIR and Orthanc servers below if they are not on ports `3000` or `8042`, respectively, or if they are not being run on `localhost`.\n",
    "\n",
    "## Notebook Structure:\n",
    "\n",
    "1. ðŸ“¦ Environment Setup\n",
    "    - Install packages (if needed)\n",
    "    - Import libraries (torch, transformers, pandas, etc.)\n",
    "\n",
    "2. ðŸ“‚ Data Access and Loading\n",
    "    - Connect to MIMIC-IV & MIMIC-CXR\n",
    "    - Decide on a small number of patients to load into the VolView Insight web app\n",
    "    - Load the corresponding MIMIC-IV FHIR resources (in MIMIC-on-FHIR) into the HAPI FHIR server\n",
    "    - Load the corresponding MIMIC-CXR data into the Orthanc server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41048261-c26f-4a63-b140-ad03b45ce2bd",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487a77eb-492b-448e-a31f-b86c68c7d7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fhirclient.models.patient import Patient\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import time\n",
    "\n",
    "PROJECT_ID = \"02-load-pt-matched-data-into-volview-insight\"\n",
    "\n",
    "# Local directory paths\n",
    "PROJECT_ROOT = Path(\"/set/this/to/a/path/containing/local\")\n",
    "MIMIC_IV_BASE = Path(\"local/physionet.org/files/mimiciv/3.1/\")\n",
    "MIMIC_CXR_BASE = Path(\"local/physionet.org/files/mimic-cxr/2.0.0/\")\n",
    "MIMIC_IV_FHIR_BASE = Path(\"local/physionet.org/files/mimic-iv-fhir/2.1/\")\n",
    "\n",
    "# Server paths\n",
    "HAPI_FHIR_BASE = \"http://localhost:3000/hapi-fhir-jpaserver/fhir/\"\n",
    "ORTHANC_BASE = \"http://localhost:8042/instances\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20af90f1-c80d-4cb1-a8a1-5419d8f796ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "# Construct paths\n",
    "data_dir = os.path.join(PROJECT_ROOT, \"data\", PROJECT_ID)\n",
    "img_dir = os.path.join(PROJECT_ROOT, \"img\", PROJECT_ID)\n",
    "results_dir = os.path.join(PROJECT_ROOT, \"results\", PROJECT_ID)\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(img_dir, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "def create_result(result: int | float | str, name_of_result_file_without_extension: str):\n",
    "    \"\"\"\n",
    "    Writes a single result to a one-column CSV file in the results directory.\n",
    "    The header and filename must match `name_of_result_file_without_extension`.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the header and filename don't match.\n",
    "    \"\"\"\n",
    "    filename = f\"{name_of_result_file_without_extension}.csv\"\n",
    "    result_file_path = os.path.join(results_dir, filename)\n",
    "\n",
    "    header = name_of_result_file_without_extension\n",
    "    with open(result_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([header])\n",
    "        writer.writerow([str(result)])\n",
    "\n",
    "    # Validation: Ensure header matches file name\n",
    "    if header != os.path.splitext(os.path.basename(result_file_path))[0]:\n",
    "        raise ValueError(\"Header must match the filename without extension.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390e0c69-ceef-4423-bdd0-f4b2a4698eef",
   "metadata": {},
   "source": [
    "## ðŸ“‚ Data Access and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37599275-cd9b-4e6b-b438-f04112fdb073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MIMIC-IV patients dataframe\n",
    "patients_df = pd.read_csv(MIMIC_IV_BASE / \"hosp/patients.csv.gz\")\n",
    "patients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9133e28-4522-4957-b5ff-b1e0647f797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MIMIC-CXR chest X-Ray records dataframe\n",
    "image_record_df = pd.read_csv(MIMIC_CXR_BASE / \"cxr-record-list.csv.gz\")\n",
    "image_record_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b1b452-4274-4b2a-87ce-8fb6bd53846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MIMIC-IV patients dataframe\n",
    "patients_df = patients_df[patients_df['subject_id'].isin(image_record_df['subject_id'])]\n",
    "patients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b87ea7-1ec5-45cf-8148-d4e51e566b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 10 patients with images\n",
    "selected_patients = patients_df.iloc[:10]['subject_id']\n",
    "selected_images = image_record_df[image_record_df['subject_id'].isin(selected_patients)][['subject_id', 'path']]\n",
    "selected_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e7065f-c941-4ab3-81e6-077863075c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, get the FHIR resources needed to load into the HAPI FHIR database. Make\n",
    "# sure to save the MimicPatient \"id\", which is the unique reference to the patient\n",
    "# as it pertains to the FHIR system from which the data was transferred. Furthermore,\n",
    "# when posting the resource to the new FHIR database, a successful POST will return\n",
    "# an automatically generated new \"id\" in the Location header. Instead, we want to use\n",
    "# the same \"id\" from the previous location. The scoped \"identifier\" is irrelevant\n",
    "# for anything here.\n",
    "\n",
    "# Convert Series to DataFrame\n",
    "if isinstance(selected_patients, pd.Series):\n",
    "    selected_patients = selected_patients.to_frame(name='subject_id')\n",
    "    \n",
    "# Add the column with default None (if it doesn't exist already)\n",
    "if 'orig_patient_reference' not in selected_patients.columns:\n",
    "    selected_patients['orig_patient_reference'] = None\n",
    "    \n",
    "headers = {\n",
    "    'Content-Type': 'application/fhir+json',\n",
    "    'Accept': 'application/fhir+json',\n",
    "    'Accept-Charset': 'UTF-8',\n",
    "}\n",
    "\n",
    "with gzip.open(MIMIC_IV_FHIR_BASE / \"fhir\" / \"MimicPatient.ndjson.gz\", 'rt') as f:\n",
    "    for line in f:\n",
    "        patient_json = json.loads(line)\n",
    "        subject_id = int(patient_json[\"identifier\"][0][\"value\"])\n",
    "        if subject_id in selected_patients['subject_id'].values:\n",
    "            patient = Patient(patient_json)\n",
    "            selected_patients.loc[selected_patients['subject_id'] == subject_id, 'orig_patient_reference'] = patient_json[\"id\"]\n",
    "            response = requests.put(f\"{HAPI_FHIR_BASE}/Patient/{patient_json['id']}\", headers=headers, json=patient.as_json())\n",
    "            print(f\"UPLOADING PATIENT {subject_id}: {response.status_code}, headers:\\n {response.headers}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65431e6-ce6a-408b-9ae3-bd4b9d02b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, load the DICOM files into the Orthanc server. Note that for each `.dcm`, the PatientID is a LO (\"Long String\") that *does* match the patient ID specified in selected_images['subject_id'].\n",
    "for idx, row in selected_images.iterrows():\n",
    "    dicom_path = MIMIC_CXR_BASE / row['path']\n",
    "\n",
    "    if not dicom_path.exists():\n",
    "        print(f\"[Warning] File not found: {dicom_path}\")\n",
    "        continue\n",
    "\n",
    "    with open(dicom_path, 'rb') as f:\n",
    "        response = requests.post(\n",
    "            ORTHANC_BASE,\n",
    "            headers={'Content-Type': 'application/dicom'},\n",
    "            data=f\n",
    "        )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Uploaded DICOM for subject {row['subject_id']}: {dicom_path.name}\")\n",
    "    else:\n",
    "        print(f\"[Error] Failed to upload {dicom_path.name}: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0856c7-b5d9-457f-9010-4b7e9515d310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC-IV on FHIR has a few extra FHIR resources which they have defined\n",
    "# themselves. We are currently only interested in the base FHIR resources; those\n",
    "# that don't require transferring the definition of the resource as well as the\n",
    "# resource.\n",
    "BASE_FHIR_RESOURCES = [\"Condition\", \"Encounter\", \"Medication\",\n",
    "\"MedicationAdministration\", \"MedicationDispense\", \"MedicationRequest\",\n",
    "\"ObservationChartevents\", \"Organization\", \"Patient\", \"Procedure\"]\n",
    "\n",
    "RESOURCE_FILES = [MIMIC_IV_FHIR_BASE / \"fhir\" / (\"Mimic\" + resource + \".ndjson.gz\") for resource in BASE_FHIR_RESOURCES if resource != \"Patient\"]\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/fhir+json',\n",
    "    'Accept': 'application/fhir+json',\n",
    "    'Accept-Charset': 'UTF-8',\n",
    "}\n",
    "\n",
    "# Upload other resources\n",
    "for file in RESOURCE_FILES:\n",
    "    resource_type = file.name.replace(\"Mimic\", \"\").replace(\".ndjson.gz\", \"\").split('.')[0]  # e.g., \"Condition\"\n",
    "    print(f\"\\nProcessing {resource_type}...\")\n",
    "\n",
    "    success_count = 0\n",
    "    start_time = time.time()  # Start timing\n",
    "\n",
    "    with gzip.open(file, 'rt') as f:\n",
    "        for line in f:\n",
    "            resource_json = json.loads(line)\n",
    "            resource_orig_id = resource_json[\"id\"]\n",
    "\n",
    "            if \"subject\" not in resource_json or \"reference\" not in resource_json[\"subject\"]:\n",
    "                print(f\"Skipping {resource_type} because the resources are not linked to patients\")\n",
    "                break\n",
    "                \n",
    "            orig_patient_reference = resource_json[\"subject\"][\"reference\"].split(\"/\")[1]\n",
    "\n",
    "            if orig_patient_reference not in selected_patients['orig_patient_reference'].values:\n",
    "                continue\n",
    "\n",
    "            response = requests.put(\n",
    "                f\"{HAPI_FHIR_BASE}/{resource_json['resourceType']}/{resource_orig_id}\",\n",
    "                headers=headers,\n",
    "                json=resource_json\n",
    "            )\n",
    "\n",
    "            if response.status_code in [200, 201]:\n",
    "                success_count += 1\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    print(f\"{success_count} {resource_type} resources successfully uploaded in {elapsed:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857b149-e799-4ec5-82b8-d19268470a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
